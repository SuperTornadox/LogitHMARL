{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import random\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "from gymnasium.spaces import Discrete, MultiDiscrete\n",
    "\n",
    "from pettingzoo import ParallelEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class warehouse_env(ParallelEnv):\n",
    "\n",
    "    \"\"\"The metadata holds environment constants.\n",
    "\n",
    "    The \"name\" metadata allows the environment to be pretty printed.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"name\": \"warehouse_env_v0\",\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"The init method takes in environment arguments.\n",
    "\n",
    "        Should define the following attributes:\n",
    "        - manager x and y coordinates\n",
    "        - picker x and y coordinates\n",
    "        - timestamp\n",
    "        - possible_agents\n",
    "\n",
    "        Note: as of v1.18.1, the action_spaces and observation_spaces attributes are deprecated.\n",
    "        Spaces should be defined in the action_space() and observation_space() methods.\n",
    "        If these methods are not overridden, spaces will be inferred from self.observation_spaces/action_spaces, raising a warning.\n",
    "\n",
    "        These attributes should not be changed after initialization.\n",
    "        \"\"\"\n",
    "        self.escape_y = None\n",
    "        self.escape_x = None\n",
    "        self.guard_y = None\n",
    "        self.guard_x = None\n",
    "        self.prisoner_y = None\n",
    "        self.prisoner_x = None\n",
    "        self.timestep = None\n",
    "        self.possible_agents = [\"manager\", \"picker\"]\n",
    "        self.height = 10 # 仓库高度\n",
    "        self.width = 10\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        pass\n",
    "\n",
    "    def step(self, actions):\n",
    "        \"\"\"Takes in an action for the current agent (specified by agent_selection).\n",
    "\n",
    "        Needs to update:\n",
    "        - prisoner x and y coordinates\n",
    "        - guard x and y coordinates\n",
    "        - terminations\n",
    "        - truncations\n",
    "        - rewards\n",
    "        - timestamp\n",
    "        - infos\n",
    "\n",
    "        And any internal state used by observe() or render()\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute actions\n",
    "        manager_action = actions[\"manager\"]\n",
    "        picker_action = actions[\"picker\"]\n",
    "\n",
    "        #经理的角色是宏观调控和任务分配，目标是优化整个系统的效率。\n",
    "        #它的动作空间应该反映其决策的核心：分配什么任务给谁（或者决定分配哪个任务。\n",
    "        #结合嵌套 Logit (NL) 策略，最核心的动作应该是：\n",
    "        # 1. 观察当前的状态，利用 NL 模型计算出每个待分配概率的选择概率决定分配哪个任务给谁 \n",
    "        # AssignTaskToPicker(task_id, picker_id)\n",
    "        # 2. 观察当前的状态，\n",
    "        \n",
    "\n",
    "        # Update picker position\n",
    "        if picker_action == \"up\" and self.picker_y > 0:\n",
    "            self.picker_y -= 1\n",
    "        elif picker_action == \"down\" and self.picker_y < self.height - 1:\n",
    "            self.picker_y += 1\n",
    "        elif picker_action == \"left\" and self.picker_x > 0:\n",
    "            self.picker_x -= 1\n",
    "        elif picker_action == \"right\" and self.picker_x < self.width - 1:\n",
    "            self.picker_x += 1\n",
    "\n",
    "        # Check termination conditions\n",
    "        terminations = {a: False for a in self.agents}\n",
    "        rewards = {a: 0 for a in self.agents}\n",
    "        if self.prisoner_x == self.guard_x and self.prisoner_y == self.guard_y:\n",
    "            rewards = {\"prisoner\": -1, \"guard\": 1}\n",
    "            terminations = {a: True for a in self.agents}\n",
    "\n",
    "        elif self.prisoner_x == self.escape_x and self.prisoner_y == self.escape_y:\n",
    "            rewards = {\"prisoner\": 1, \"guard\": -1}\n",
    "            terminations = {a: True for a in self.agents}\n",
    "\n",
    "        # Check truncation conditions (overwrites termination conditions)\n",
    "        truncations = {a: False for a in self.agents}\n",
    "        if self.timestep > 100:\n",
    "            rewards = {\"prisoner\": 0, \"guard\": 0}\n",
    "            truncations = {\"prisoner\": True, \"guard\": True}\n",
    "        self.timestep += 1\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def observation_space(self, agent):\n",
    "        return self.observation_spaces[agent]\n",
    "\n",
    "    def action_space(self, agent):\n",
    "        return self.action_spaces[agent]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LogitHMARL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
